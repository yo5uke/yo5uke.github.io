{
  "hash": "1806ba02c6e6a34cf6de08d794eb4199",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: DuckDBをR・Pythonで使う【duckplyrも】\ndescription: |\n  軽量・高速な組み込み型データベースDuckDBの使い方を、RとPythonの両方で解説します。\ndate: 2025-09-19\ndate-modified: 2026-02-01\ncategories:\n  - R\n  - Python\n  - SQL\n  - データ処理\naliases:\n- /pages/tips/250919_duckdb/index.html\n---\n\n## はじめに\n\n大量のデータを扱う際、メモリ制限やパフォーマンスの問題に直面することがあります。そんなとき便利なのが、**軽量で高速な組み込み型データベース DuckDB** です。本記事では、RとPythonの両方でDuckDBを使う方法を体系的に解説します。\n\n## DuckDBとは\n\nDuckDBは、**組み込み型のSQLデータベース**であり、特に分析ワークロードに最適化されています。SQLiteのように軽量でありながら、大規模なデータセットを効率的に処理できる点が特徴です。\n\n**組み込み型データベース**とは、アプリケーションに組み込まれて動作するデータベースのことです。PostgreSQLなどのサーバー型とは異なり、外部のデータベースサーバーを必要とせず、**R/Python上で完結**します。\n\nまた、DuckDBは**列指向ストレージ**を採用しています。データを行ではなく列ごとに格納するため、特定の列に対するクエリが高速に処理されます。列指向については、以下の記事でも触れています。\n\n{{< linkcard url=\"/pages/blog/2025/07/250728_parquet/index.qmd\" >}}\n\n## インストール\n\n:::{.panel-tabset}\n## R\n\n`duckdb`パッケージをインストールします。\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# install.packages(\"pak\")\npak::pak(\"duckdb\")\n```\n:::\n\n\nもしくは\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages(\"duckdb\")\n```\n:::\n\n\n## Python\n\n`duckdb`パッケージをインストールします。\n\n```python\n# pipを使用する場合\npip install duckdb\n\n# uvを使用する場合\nuv add duckdb\n```\n\nuvについては以下の記事をご参照ください。\n\n{{< linkcard url=\"/pages/tips/2025/09/250926_virtual_environment/index.qmd\" >}}\n:::\n\n## 基本的な使い方\n\n### データベースへの接続\n\nDuckDBには**メモリ内データベース**と**永続データベース**の2種類があります。\n\n- **メモリ内データベース**: セッション終了時にデータが消去される。一時的な分析に便利。\n- **永続データベース**: `.duckdb`ファイルにデータが保存され、セッションを跨いで再利用できる。\n\n:::{.panel-tabset}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(duckdb)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# メモリ内データベースに接続\ncon <- dbConnect(duckdb())\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 永続データベースに接続\ncon <- dbConnect(duckdb(), dbdir = here::here(\"data/iris.duckdb\"))\n```\n:::\n\n\n永続データベースの場合、指定したパスに`.duckdb`ファイルが作成されます。\n\n## Python\n\n```python\nimport duckdb\n\n# メモリ内データベースに接続\ncon = duckdb.connect()\n\n# 永続データベースに接続する場合\ncon = duckdb.connect('data/iris.duckdb')\n```\n:::\n\n### データの読み込み\n\nDuckDBはCSVやParquetなど、様々なデータ形式を直接読み込めます。ここではCSVファイルの読み込みを例に紹介します。\n\n#### SQLで読み込む\n\n:::{.panel-tabset}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndbExecute(con, \"CREATE TABLE iris AS SELECT * FROM read_csv('data/iris.csv')\")\n```\n:::\n\n\n## Python\n\n```python\ncon.sql(\"CREATE TABLE iris AS SELECT * FROM read_csv('data/iris.csv')\")\n```\n:::\n\nこのSQL文は、`read_csv('data/iris.csv')`から全列（`*`）を選択し、`iris`という名前のテーブルを作成しています。\n\nこの方法のメリットは、**R/Pythonに一度もデータを読み込まずに、DuckDBが直接ファイルを処理できる**点です。R/Pythonに読み込まれるのはクエリの結果だけなので、メモリ消費を抑えられます。また、`CREATE TABLE ... AS SELECT ...`構文で、列の選択やフィルタリングなどの前処理を行いながらテーブルを作成できます。\n\n#### [dplyr]{.fira-code}で読み込む（R限定）{#sec-dplyr-load}\n\nSQLになじみがない方向けに、Rでは`dplyr`を使ったデータベース操作も可能です。`dplyr`で書いたコードが裏でSQLに変換・実行されます。\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Rでデータを読み込み、DuckDBに登録\niris_data <- read_csv(here::here(\"data/iris.csv\"))\nduckdb_register(con, iris, \"iris_data\")\n```\n:::\n\n\n`duckdb_register()`は、RのデータフレームをDuckDB上のテーブルとして登録します。これをすると、`dbGetQuery()`や`tbl()`で`iris`テーブルを参照できるようになります。\n\n永続データベースに書き込みたい場合は、代わりに`dbWriteTable()`を使います。\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndbWriteTable(con, \"iris\", iris_data)\n```\n:::\n\n\n永続データベースに書き込めば、1つの`.duckdb`ファイルに複数のテーブルを保存でき、後で再利用できます。\n\n:::{.callout-note}\nSQLで直接ファイルを読む方法とは異なり、`dplyr`経由では一度Rにデータを読み込んでからデータベースに登録するため、大きなデータではメモリ消費が増える点に注意してください。\n:::\n\nなお、データベースにはテーブルを複数作成できるので、`iris`以外のデータも好きな名前で追加できます^[とはいえ、プロジェクトごとなどで`.duckdb`は分けた方が良いとは思います。]。\n\n### 遅延評価について\n\nデータベースを使うメリットのひとつに、**遅延評価（lazy evaluation）**があります。通常のデータ処理では書いた順に即座に実行されますが、DuckDBでは処理を記録しておき、最後にまとめて実行します。\n\n```\n通常：データ読み込み → 処理を即実行 → 結果を返す\n遅延評価：データ読み込み → 処理を記録 → まとめて実行（SQL発行）→ 結果を返す\n```\n\nこのおかげで不要な計算が省かれ、大規模データでも効率的に処理できます。\n\n### データの操作\n\n#### SQLで操作する\n\n:::{.panel-tabset}\n## R\n\n::: {.cell}\n\n```{.r .cell-code}\nresult <- dbGetQuery(con, \"SELECT * FROM iris WHERE Species = 'setosa'\")\n```\n:::\n\n\n## Python\n```python\nresult = con.sql(\"SELECT * FROM iris WHERE Species = 'setosa'\")\n```\n:::\n\nこの例では、`iris`テーブルから`Species`が`setosa`の行を取得しています。\n\n#### dplyrで操作する（R限定）\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresult <- tbl(con, \"iris\") |>\n  filter(Species == \"setosa\") |>\n  collect()\n```\n:::\n\n\n`tbl(con, \"iris\")`でデータベース上のテーブルを参照し、`filter()`などおなじみの`dplyr`関数で操作できます。\n\nここで重要なのは、**`collect()`を呼び出すまではSQLが実行されない**という点です。`filter()`などの処理を重ねるたびに裏でSQLクエリが組み立てられ、`collect()`で初めて実行されます。つまり、`collect()`の前まではデータはRに読み込まれず、「SQLを組み立てているだけ」の状態です。\n\nデータベースになじみがない方にとっては少し不思議かもしれませんが、`con`はデータそのものではなく、**データベースへの接続（窓口）**を表すオブジェクトです。この窓口を通してテーブルを参照し、最終的に`collect()`で結果を手元に取り込む、という流れになります。\n\n### テーブルの削除\n\n:::{.panel-tabset}\n## R\n\n::: {.cell}\n\n```{.r .cell-code}\n# テーブルを削除\ndbExecute(con, \"DROP TABLE iris\")\n\n# テーブルが存在しない場合でもエラーにならない書き方\ndbExecute(con, \"DROP TABLE IF EXISTS iris\")\n```\n:::\n\n\n## Python\n```python\n# テーブルを削除\ncon.sql(\"DROP TABLE iris\")\n\n# テーブルが存在しない場合でもエラーにならない書き方\ncon.sql(\"DROP TABLE IF EXISTS iris\")\n```\n:::\n\n### データベースからの切断\n\n操作が終わったら、接続を切断します。\n\n:::{.panel-tabset}\n## R\n\n::: {.cell}\n\n```{.r .cell-code}\ndbDisconnect(con, shutdown = TRUE)\n```\n:::\n\n\n`shutdown = TRUE`を指定すると、メモリ内データベースの場合はデータが消去され、ファイルベースの場合は接続が閉じられます。\n\n## Python\n```python\ncon.close()\n```\n:::\n\n## {duckplyr}を使う（R限定）\n\nここまではDuckDBをデータベースとして使う方法を紹介してきましたが、Rには`duckplyr`というもうひとつのアプローチがあります。\n\n### duckplyrとは\n\n`duckplyr`は、**dplyrのドロップイン置き換え**として機能するパッケージです。`library(duckplyr)`するだけで、既存のdplyrコードがそのまま動きながら、裏側でDuckDBの高速な分析エンジンが使われます。\n\n### duckdbパッケージとの違い\n\n| | duckdb + dbplyr | duckplyr |\n|---|---|---|\n| データベース接続 | 必要 | **不要** |\n| データの場所 | DB上（`collect()`でRへ） | Rのメモリ上 |\n| 仕組み | dplyr → SQL翻訳 → DuckDB実行 | Rのデータを直接DuckDBエンジンで処理 |\n| 用途 | 大規模データのDB管理・分析 | メモリ内データの高速化 |\n\n**duckdb + dbplyr** は、データベースに接続してSQLベースで処理する方法（[前のセクション](#sec-dplyr-load)で紹介）、**duckplyr** は、データベースを意識せずに、普段のdplyrコードをそのまま高速化する方法です。\n\n### duckplyrの特徴\n\n1. **ドロップイン置き換え**: `library(duckplyr)`するだけで、多くのdplyr動詞が高速化される\n2. **自動フォールバック**: 対応できない操作は自動的に通常のdplyrにフォールバックするため、エラーで止まらない\n3. **大規模データに最適**: DuckDBの並列処理エンジンとメモリ効率の良い処理を活用\n4. **互換性**: tidyverseエコシステムとシームレスに連携\n\n### 使用例\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(duckplyr)\n#> Loading required package: dplyr\n#> ✔ Overwriting dplyr methods with duckplyr methods.\n#> ℹ Turn off with `duckplyr::methods_restore()`.\n\n# 通常のdplyr構文がそのまま使えます\nmtcars |>\n  group_by(cyl) |>\n  summarise(\n    mean_mpg = mean(mpg),\n    mean_hp = mean(hp),\n    .groups = \"drop\"\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 3\n    cyl mean_mpg mean_hp\n  <dbl>    <dbl>   <dbl>\n1     4     26.7    82.6\n2     6     19.7   122. \n3     8     15.1   209. \n```\n\n\n:::\n:::\n\n\n:::{.callout-important}\n**読み込み順序が重要です。** `library(tidyverse)`の後に`library(duckplyr)`を読み込んでください。逆の順序だと、通常のdplyrが優先されてしまいます。\n:::\n\n小さいデータだと速さを実感しにくいかもしれませんが、大きいデータを扱うときに効果を発揮します。\n\n## まとめ\n\nDuckDBは軽量で高速な組み込み型データベースであり、R/Python上で手軽に大規模データを扱えます。\n\n- **SQL**で直接ファイルを読み込み・操作する方法が、最もメモリ効率が良い\n- Rでは**dplyr**を使ったデータベース操作も可能で、SQLに不慣れでも扱いやすい\n- さらにRでは**duckplyr**を使えば、既存のdplyrコードをほぼそのまま高速化できる\n\nぜひお試しあれ。\n\n## 参考\n\n{{< linkcard url=\"https://duckdb.org/docs/stable/\" >}}\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}